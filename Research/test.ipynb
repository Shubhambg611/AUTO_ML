{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import IsolationForest\n",
    "file_path = 'D:/AUTO_ML/data/fish_data.csv'\n",
    "def preprocess_data(file_path):\n",
    "    # Load the dataset\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Display basic info\n",
    "    print(\"Original Data:\")\n",
    "    print(df.info())\n",
    "\n",
    "    # Remove duplicates\n",
    "    df.drop_duplicates(inplace=True)\n",
    "\n",
    "    # Remove outliers using Isolation Forest\n",
    "    isolation_forest = IsolationForest(contamination=0.05)\n",
    "    outliers = isolation_forest.fit_predict(df.select_dtypes(include=[np.number]))\n",
    "    df = df[outliers == 1]\n",
    "\n",
    "    # Identify numerical and categorical columns\n",
    "    numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "    # Preprocessing pipeline\n",
    "    numerical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='mean')),  # Fill missing values\n",
    "        ('scaler', StandardScaler())                   # Standardization\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),  # Fill missing values\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))      # One-hot encoding\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numerical_transformer, numerical_cols),\n",
    "            ('cat', categorical_transformer, categorical_cols)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Fit and transform the data\n",
    "    X_preprocessed = preprocessor.fit_transform(df)\n",
    "\n",
    "    # Create a DataFrame with the preprocessed data\n",
    "    # Get feature names after encoding\n",
    "    cat_feature_names = preprocessor.named_transformers_['cat']['onehot'].get_feature_names_out(categorical_cols)\n",
    "    all_feature_names = np.concatenate([numerical_cols, cat_feature_names])\n",
    "\n",
    "    X_preprocessed_df = pd.DataFrame(X_preprocessed, columns=all_feature_names)\n",
    "\n",
    "    print(\"\\nPreprocessed Data:\")\n",
    "    print(X_preprocessed_df.info())\n",
    "\n",
    "    return X_preprocessed_df\n",
    "\n",
    "# Example usage\n",
    "# preprocessed_data = preprocess_data('path_to_your_file.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>length</th>\n",
       "      <th>weight</th>\n",
       "      <th>w_l_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anabas testudineus</td>\n",
       "      <td>10.66</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Anabas testudineus</td>\n",
       "      <td>6.91</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Anabas testudineus</td>\n",
       "      <td>8.38</td>\n",
       "      <td>3.46</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anabas testudineus</td>\n",
       "      <td>7.57</td>\n",
       "      <td>3.36</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anabas testudineus</td>\n",
       "      <td>10.83</td>\n",
       "      <td>3.38</td>\n",
       "      <td>0.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4075</th>\n",
       "      <td>Sillaginopsis panijus</td>\n",
       "      <td>30.56</td>\n",
       "      <td>6.12</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4076</th>\n",
       "      <td>Sillaginopsis panijus</td>\n",
       "      <td>29.66</td>\n",
       "      <td>6.11</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4077</th>\n",
       "      <td>Sillaginopsis panijus</td>\n",
       "      <td>32.81</td>\n",
       "      <td>6.25</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4078</th>\n",
       "      <td>Sillaginopsis panijus</td>\n",
       "      <td>29.78</td>\n",
       "      <td>6.11</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4079</th>\n",
       "      <td>Sillaginopsis panijus</td>\n",
       "      <td>31.62</td>\n",
       "      <td>6.14</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4080 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    species  length  weight  w_l_ratio\n",
       "0        Anabas testudineus   10.66    3.45       0.32\n",
       "1        Anabas testudineus    6.91    3.27       0.47\n",
       "2        Anabas testudineus    8.38    3.46       0.41\n",
       "3        Anabas testudineus    7.57    3.36       0.44\n",
       "4        Anabas testudineus   10.83    3.38       0.31\n",
       "...                     ...     ...     ...        ...\n",
       "4075  Sillaginopsis panijus   30.56    6.12       0.20\n",
       "4076  Sillaginopsis panijus   29.66    6.11       0.21\n",
       "4077  Sillaginopsis panijus   32.81    6.25       0.19\n",
       "4078  Sillaginopsis panijus   29.78    6.11       0.21\n",
       "4079  Sillaginopsis panijus   31.62    6.14       0.19\n",
       "\n",
       "[4080 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"D:/AUTO_ML/data/fish_data.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "def preprocess_data(file_path):\n",
    "    # Load the dataset\n",
    "    try:\n",
    "        df = pd.read_csv(\"D:/AUTO_ML/data/fish_data.csv\")\n",
    "        print(\"Original Data:\")\n",
    "        print(df.head())  # Display the first few rows\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        return None\n",
    "\n",
    "    # Remove duplicates\n",
    "    df.drop_duplicates(inplace=True)\n",
    "\n",
    "    # Outlier removal using Isolation Forest\n",
    "    isolation_forest = IsolationForest(contamination=0.05)\n",
    "    outliers = isolation_forest.fit_predict(df.select_dtypes(include=[np.number]))\n",
    "    df = df[outliers == 1]\n",
    "\n",
    "    # Identify numerical and categorical columns\n",
    "    numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "    # Check if there are any categorical columns\n",
    "    if not categorical_cols:\n",
    "        print(\"No categorical columns found.\")\n",
    "    else:\n",
    "        print(\"Categorical columns:\", categorical_cols)\n",
    "\n",
    "    # Preprocessing pipeline\n",
    "    numerical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='mean')),  # Fill missing values\n",
    "        ('scaler', StandardScaler())                   # Standardization\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),  # Fill missing values\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))      # One-hot encoding\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numerical_transformer, numerical_cols),\n",
    "            ('cat', categorical_transformer, categorical_cols)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Fit and transform the data\n",
    "    try:\n",
    "        X_preprocessed = preprocessor.fit_transform(df)\n",
    "\n",
    "        # Create a DataFrame with the preprocessed data\n",
    "        cat_feature_names = preprocessor.named_transformers_['cat']['onehot'].get_feature_names_out(categorical_cols)\n",
    "        all_feature_names = np.concatenate([numerical_cols, cat_feature_names])\n",
    "\n",
    "        X_preprocessed_df = pd.DataFrame(X_preprocessed, columns=all_feature_names)\n",
    "\n",
    "        print(\"\\nPreprocessed Data:\")\n",
    "        print(X_preprocessed_df.head())  # Display the first few rows of preprocessed data\n",
    "    except Exception as e:\n",
    "        print(f\"Error during preprocessing: {e}\")\n",
    "        return None\n",
    "\n",
    "    return X_preprocessed_df\n",
    "\n",
    "# Example usage\n",
    "# preprocessed_data = preprocess_data('path_to_your_file.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_preprocessed_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mX_preprocessed_df\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_preprocessed_df' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "def preprocess_data(file_path):\n",
    "    # Load the dataset\n",
    "    try:\n",
    "        df = pd.read_csv(\"D:/AUTO_ML/data/fish_data.csv\")\n",
    "        print(\"Original Data Loaded Successfully\")\n",
    "        print(\"Shape of Original Data:\", df.shape)\n",
    "        print(\"First few rows of the original data:\")\n",
    "        print(df.head())  # Display the first few rows\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        return None\n",
    "\n",
    "    # Remove duplicates\n",
    "    df.drop_duplicates(inplace=True)\n",
    "\n",
    "    # Outlier removal using Isolation Forest\n",
    "    isolation_forest = IsolationForest(contamination=0.05)\n",
    "    outliers = isolation_forest.fit_predict(df.select_dtypes(include=[np.number]))\n",
    "    df = df[outliers == 1]\n",
    "    print(\"Outliers removed. New shape of data:\", df.shape)\n",
    "\n",
    "    # Identify numerical and categorical columns\n",
    "    numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "    # Debugging: Print identified columns\n",
    "    print(\"Numerical columns:\", numerical_cols)\n",
    "    print(\"Categorical columns:\", categorical_cols)\n",
    "\n",
    "    # Preprocessing pipeline\n",
    "    numerical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='mean')),  # Fill missing values\n",
    "        ('scaler', StandardScaler())                   # Standardization\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),  # Fill missing values\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))      # One-hot encoding\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numerical_transformer, numerical_cols),\n",
    "            ('cat', categorical_transformer, categorical_cols)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Fit and transform the data\n",
    "    try:\n",
    "        X_preprocessed = preprocessor.fit_transform(df)\n",
    "\n",
    "        # Create a DataFrame with the preprocessed data\n",
    "        cat_feature_names = preprocessor.named_transformers_['cat']['onehot'].get_feature_names_out(categorical_cols)\n",
    "        all_feature_names = np.concatenate([numerical_cols, cat_feature_names])\n",
    "\n",
    "        X_preprocessed_df = pd.DataFrame(X_preprocessed, columns=all_feature_names)\n",
    "\n",
    "        print(\"\\nPreprocessed Data:\")\n",
    "        print(X_preprocessed_df.head())  # Display the first few rows of preprocessed data\n",
    "        print(\"Shape of Preprocessed Data:\", X_preprocessed_df.shape)\n",
    "    except Exception as e:\n",
    "        print(f\"Error during preprocessing: {e}\")\n",
    "        return None\n",
    "\n",
    "    return X_preprocessed_df\n",
    "\n",
    "# Example usage\n",
    "# preprocessed_data = preprocess_data('path_to_your_file.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
